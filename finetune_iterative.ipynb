{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb326ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Domain Generation with T5 and MLflow\n",
    "#This notebook demonstrates how to fine-tune a T5 model for domain name generation \n",
    "#using the Transformers library and track experiments with MLflow.\n",
    "#The only feature about this script is to be able to use older fine tuned model for further iteration\n",
    "#This was experimental, this could be easily deleted and we can use finetune_mlflow.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e959b2c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2051941148.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython3 -m venv venv\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create a new virtual environment\n",
    "python3 -m venv venv\n",
    "\n",
    "# On macOS/Linux, activate it:\n",
    "source venv/bin/activate\n",
    "\n",
    "#install the requirements\n",
    "pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aacbe6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj/personal_projects/domain_generator/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import all the required packages\n",
    "import json\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import os\n",
    "from utils import Utils\n",
    "from evaluation_framework import QuickEvaluator\n",
    "\n",
    "eval = QuickEvaluator()\n",
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016e6e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset {'input_text': ['Generate domain names for this business: strategy specializing in operational efficiency', 'Generate domain names for this business: Modern group travel solutions', 'Generate domain names for this business: inventory tracking for marketers', 'Generate domain names for this business: Online estate planning platform', 'Generate domain names for this business: Modern divorce proceedings solutions', 'Generate domain names for this business: premium custom food blogging for busy professionals', 'Generate domain names for this business: new professional wellness coaching company', 'Generate domain names for this business: Local home offering landscaping', 'Generate domain names for this business: new skincare specializing in hair styling', 'Generate domain names for this business: Professional learning management company'], 'target_text': ['strategyexperts.org, strategyio.dev, operationalapp.tech, sparklab.app, specializingio.ly', 'apppro.app, modernescape.ai, modernescape.me, modernadventure.ly, modernhub.com', 'integrationco.co, syncsoftware.dev, trackingtech.co, inventoryly.com, analyticshub.co', 'legaladvice.dev, expertlegal.me, professionallaw.app, legallegal.app, planninglaw.io', 'flowco.co, modernio.me, proceedingspro.me, divorceapp.io, attorneydefense.org', 'syncco.me, customapp.app, premiumfeast.co, mealdish.io, dailycooking.me', 'wellnessmedical.me, appio.dev, dashly.io, preventionlife.ai, therapymedical.tech', 'dashmax.tech, homeapp.app, homecare.com, homerepair.ai, houseservices.org', 'hairpro.ly, divinecosmetics.org, salonperfect.ly, fluxhub.co, groomingsalon.app', 'dashpro.co, edutraining.ly, smarttraining.ai, skillcourse.ai, learneducation.app']}\n",
      "\n",
      "\n",
      "eval_dataset {'input_text': ['Generate domain names for this business: premium repair', 'Generate domain names for this business: new online home cleaning platform', 'Generate domain names for this business: wine bar with quick service', 'Generate domain names for this business: Professional cryptocurrency trading company', 'Generate domain names for this business: Custom customer relationship management for small businesses', 'Generate domain names for this business: family-owned custom real estate law for startups', 'Generate domain names for this business: organic creative', 'Generate domain names for this business: Fortune 500 companies-focused change management', 'Generate domain names for this business: Affordable food delivery option', 'Generate domain names for this business: Custom landscape photography for businesses'], 'target_text': ['premiumhouse.com, perfectrepair.ai, repairservices.com, appio.tech, expertrepair.ly', 'homeimprovement.ai, homepro.com, novalab.io, househome.dev, onlineservices.ly', 'kitchenbites.dev, servicedine.ly, brewerycafe.io, appify.ai, gourmetdiner.app', 'zoomai.org, wealthwealth.org, lendingfinance.ai, tradingapp.app, smartfinancial.app', 'appapp.app, relationshipco.me, systemio.org, customertech.app, tooltech.ai', 'familylaw.io, zetalab.co, advocacylegal.com, dashio.ly, familyco.dev', 'creativevision.tech, axislab.me, photoslens.tech, capturephotos.io, syncify.app', 'flowlab.ai, fortuneco.org, advisoryexperts.org, fortuneexperts.org, fortuneguidance.com', 'deliverytaste.ai, novaify.app, foodpro.app, biterestaurant.ly, quickcooking.ai', 'sparkhub.com, landscapepro.ai, fluxco.org, customcapture.com, framecamera.com']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████| 4500/4500 [00:01<00:00, 2768.27 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1355.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Domain Generation Experiment\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "#The number of total_samples determines the model name, we could use 5000 as a variable for future iterations\n",
    "model_name = f\"flan-t5-domain-generator-final-5000\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(f\"./models/{model_name}\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(f\"./models/{model_name}\")\n",
    "\n",
    "# Load your training data\n",
    "training_data_path = \"data/edge-cases/data-addendum/training-data.jsonl\"\n",
    "training_data = Utils().load_jsonl(file_path=training_data_path)\n",
    "\n",
    "# Format data for T5 (instruction format)\n",
    "def format_data(data):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in data:\n",
    "        # Create instruction-style input\n",
    "        input_text = f\"Generate domain names for this business: {i['input']}\"\n",
    "        inputs.append(input_text)\n",
    "        targets.append(i['output'])\n",
    "    \n",
    "    return {\"input_text\": inputs, \"target_text\": targets}\n",
    "\n",
    "# Prepare datasets\n",
    "formatted_data = format_data(training_data)\n",
    "train_data, eval_data = train_test_split(\n",
    "    list(zip(formatted_data[\"input_text\"], formatted_data[\"target_text\"])), \n",
    "    test_size=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_inputs, train_targets = zip(*train_data)\n",
    "eval_inputs, eval_targets = zip(*eval_data)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_text\": train_inputs,\n",
    "    \"target_text\": train_targets\n",
    "})\n",
    "print(\"train_dataset\", train_dataset[0:10])\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"input_text\": eval_inputs,\n",
    "    \"target_text\": eval_targets\n",
    "})\n",
    "print(\"\\n\\neval_dataset\", eval_dataset[0:10])\n",
    "\n",
    "# Tokenization function\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    labels = tokenizer(\n",
    "        examples[\"target_text\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Validation preprocessing function\n",
    "def preprocess_validation_function(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    labels = tokenizer(\n",
    "        examples[\"target_text\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca7a64",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_version\", mlflow.active_run().info.run_id)\n",
    "    mlflow.log_param(\"model_name\", model_name)\n",
    "    mlflow.log_param(\"train_size\", len(train_dataset))\n",
    "    mlflow.log_param(\"eval_size\", len(eval_dataset))\n",
    "    \n",
    "    # Training code\n",
    "    # Training arguments optimized for creativity\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./flan-t5-domain-generator-iterative\",\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        learning_rate=3e-4,  # Higher learning rate for T5\n",
    "        warmup_steps=10,\n",
    "        logging_steps=5,\n",
    "        eval_steps=15,\n",
    "        save_steps=15,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "        report_to=None,\n",
    "        dataloader_pin_memory=False\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    print(\"Saving model...\")\n",
    "    #create models directory if it doesn't exist\n",
    "    os.makedirs(\"./models\", exist_ok=True)\n",
    "    #The number of total_samples determines the model name\n",
    "    old_train_samples = 5000\n",
    "    new_training_samples = len(training_data)\n",
    "    total_samples = old_train_samples + new_training_samples\n",
    "    trainer.save_model(f\"./models/flan-t5-domain-generator-final-{total_samples}\")\n",
    "    tokenizer.save_pretrained(f\"./models/flan-t5-domain-generator-final-{total_samples}\")\n",
    "    print(\"Training completed and model saved!\")\n",
    "\n",
    "\n",
    "    input_example = {\n",
    "        \"input_text\": [\"Generate domain names for this business: premium coffee roasting business\"]\n",
    "    }\n",
    "    # Log model\n",
    "    mlflow.pytorch.log_model(model, f\"model-{total_samples}\", input_example=input_example)\n",
    "\n",
    "    print(\"Predicting domains and running evaluation\")\n",
    "    validation_data = []\n",
    "    eval_samples = 100\n",
    "    eval_data_file_name = \"./data/eval-data/data_eval_100.json\"\n",
    "    with open(eval_data_file_name, \"r\") as f:\n",
    "        validation_data = json.load(f)\n",
    "    # Extract inputs and targets from validation data\n",
    "    validation_inputs = [item[\"business_description\"] for item in validation_data]\n",
    "    validation_targets = [item[\"domain_suggestions\"] for item in validation_data]\n",
    "\n",
    "    # Create validation dataset\n",
    "    validation_dataset = Dataset.from_dict({\n",
    "        \"input_text\": validation_inputs,\n",
    "        \"target_text\": validation_targets\n",
    "    })\n",
    "    input_texts = list(validation_dataset[\"input_text\"])\n",
    "    # Convert input texts to input IDs and attention masks\n",
    "    inputs = tokenizer(\n",
    "        input_texts,\n",
    "        return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # use fine tuned model to predict domains for the validation dataset\n",
    "    fine_tuned_model_name = f\"flan-t5-domain-generator-final-{total_samples}\"\n",
    "    fine_tuned_model = T5ForConditionalGeneration.from_pretrained(f\"./models/{fine_tuned_model_name}\")\n",
    "    generated_domains = fine_tuned_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=128,\n",
    "        num_return_sequences=1\n",
    "        )\n",
    "    decoded_domains = [tokenizer.decode(g, skip_special_tokens=True) for g in generated_domains]\n",
    "    #save the data to a file\n",
    "    file_name = f\"./data/eval-data/predicted_domains_and_ground_truth_{total_samples}_{fine_tuned_model_name}.json\"\n",
    "    with open(file_name, \"w\") as f:\n",
    "        json.dump(decoded_domains, f)\n",
    "\n",
    "    #evaluate the generated domains\n",
    "    all_domains = utils.clean_decoded_domains(decoded_domains)\n",
    "    all_data, scores = [], []\n",
    "    for i in range(len(all_domains)):\n",
    "        if i%10 == 0:\n",
    "            print(f\"Evaluating {i} of {len(all_domains)} business descriptions\")\n",
    "        business_desc = validation_data[i]['business_description']\n",
    "        domains = all_domains[i]\n",
    "        industry = validation_data[i]['industry']\n",
    "        all_data.append({\n",
    "            'business_description': business_desc,\n",
    "            'ground_truth_domains': validation_data[i]['domain_suggestions'],\n",
    "            'industry': industry,\n",
    "            'predicted_domains': domains,\n",
    "            'evaluation_results': eval.fine_tuned_calculate_overall_score(business_desc, domains)\n",
    "        })\n",
    "        scores.append(eval.fine_tuned_calculate_overall_score(business_desc, domains)['overall_score'])\n",
    "\n",
    "    average_score = sum(scores)/len(scores)\n",
    "    utils.save_final_metric(average_score, fine_tuned_model_name, eval_samples, eval_data_file_name)\n",
    "    #log the average score to mlflow\n",
    "    mlflow.log_metric(f\"average_score_on_eval_data_{eval_samples}\", average_score)\n",
    "\n",
    "    #save the data to a json file\n",
    "    with open(file_name, \"w\") as f:\n",
    "        json.dump(all_data, f, indent=4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
